# Overfitting & Underfitting in Neural Networks

Neural networks are prone to **overfitting**.

### Why?

Neural networks are **high-capacity models** ‚Äî they can learn very complex **patterns**, including **noise** in the training data.

The decision boundary **fits the data too well**. It starts becoming **highly non-linear** to adapt to small fluctuations in the data.

---

### üìà Causes of Overfitting:
- Too many layers or neurons: High capacity models can learn noise.
- Not enough training data
- Too many training epochs

### üö® Signs of Overfitting:
- Low training error, but
- High validation/test error

> We need to make sure that the NN doesn‚Äôt fit the noise in the data.

---

Neural networks can also be prone to **underfitting**, though it's less common in practice.

Underfitting happens when a neural network fails to learn the underlying patterns in the data.  
It performs poorly on both the training and test sets.

---

### üß± Causes of Underfitting:
- Insufficient training: Not enough epochs
- Model too simple: The architecture has too few layers or neurons

### üõë Signs of Underfitting:
- Training Loss ‚Üí High  
- Validation Loss ‚Üí High

## Bias-Variance Tradeoff

> It describes the balance between **underfitting** and **overfitting**.

---

| **Term**   | **What it Means**                                      | **Problem It Causes** |
|------------|--------------------------------------------------------|------------------------|
| **Bias**   | Error due to oversimplifying the model                 | Underfitting           |
| **Variance** | Error due to too much sensitivity to training data     | Overfitting            |

---

### üìä Understanding Variance

- **Variance** refers to how much the model's predictions change when trained on different datasets.
- It‚Äôs a property of the **model**, indicating sensitivity to training data.
- **High variance** model: Very sensitive ‚Üí overfits (fits noise)
- **Low variance** model: More stable ‚Üí generalizes better

---

### ‚úÖ A Robust Model:
- Has the **best training**, **validation**, and **test** accuracy

---

### ‚öôÔ∏è Mechanisms to Control Overfitting/Underfitting:
- Control number of **neurons**
- Control number of **layers**
- Choose appropriate **activation functions**
- Select suitable **optimizers**
- Proper **weight initialization**
- Use **regularization**
- Apply **dropout**
- Use **batch normalization**

